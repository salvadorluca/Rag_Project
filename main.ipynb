{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set the working directory to scripts in order to import the different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from find_alpha import linear_search_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do query rewriting you would need an open ai api key, otherwise run this cell as is without filling it. \\\n",
    "Also if you want to generate train and test set as we generated it you need this key, but we advise to download our already generated train and test set from [here](https://epflch-my.sharepoint.com/:f:/g/personal/marco_giuliano_epfl_ch/EomT1E_2ZaFCkB7zpx-jDAMBxLz6UP8NGtdBNvK10RaYHQ?e=w8s5QY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"sk-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use reranking you will need a cohere api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_api_key = \"COHERE_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you can choose between the different model architectures we explained in the report. \\\n",
    "To use BM25 set \"BM25\" \\\n",
    "To use BGE set \"BGE\" \\\n",
    "To use finetuned BGE set retriever_model to \"BGE_Finetuned\" \\\n",
    "To use hybrid search set \"Hybrid_BGE\" and \"Hybrid_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = \"BM25\"\n",
    "query_rewriting = True\n",
    "reranking = False\n",
    "top_k = 10\n",
    "alpha = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To evaluate the different models run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = EmbeddingQAFinetuneDataset.from_json(\"../test_dataset_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval= evaluate(test_data,\n",
    "    retriever_model,\n",
    "    top_k=top_k,\n",
    "    verbose=True,\n",
    "    query_rewriting=query_rewriting,\n",
    "    reranking=reranking,\n",
    "    alpha=alpha,\n",
    "    top_k_before_reranking= 50,\n",
    "    openai_api_key= openai_api_key,\n",
    "    cohere_api_key= cohere_api_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear search for alpha in case of hybrid search:\n",
    "Find best alpha parameter, the retriever model should be either \"Hybrid_BGE\" or \"Hybrid_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = EmbeddingQAFinetuneDataset.from_json(\"../val_dataset_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65 , 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "alphas_score = linear_search_alpha(val_data, retriever_model, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = max(alphas_score, key = alphas_score.get)\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating train and test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_train_val_test import create_train_val_test\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ashraq/financial-news-articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function you can recreate the train and test dataset that we have, but you would need an Openai api key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create train set, set split = \"train\" \\\n",
    "To create val set, set split = \"val\" \\\n",
    "To create test set, set split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = openai_api_key #IF you have not set the openai api key in the previous cell, you can set it here as \"sk-\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_val_test(ds, split, openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune BGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can finetune yourself the BGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from finetuning import finetune_BGE\n",
    "\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"../train_dataset_new.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"../val_dataset_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_BGE(train_dataset, val_dataset, \"../models/BGE_Finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
